
During my fellowship, my group and I completed the Ames Housing Dataset Kaggle Competition in order to explore the machine learning material we had covered to date.

Topics explored included:

- Exploratory Data Analysis
	* Variable Distribution
	* Variable Correlation
- Feature Engineering
	* Log Transformation
	* Imputation
	* One-Hot Encoding
- Linear Models 
	* Lasso
	* Ridge
	* ElasticNet
- Tree Based Models
	* Random Forests
	* Gradient Boosting Machines
	* Tuning Hyperparameters
	* Variable Importance
	* Cross-Validation
- Ensembling Methods
	* Stacking

Our top model was a stacked model and ranked in the top 15% on the Public Leaderboard as of the time of submission as determined by RMSLE. 
